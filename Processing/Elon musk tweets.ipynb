{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e3fa9e-0070-44e2-90c0-5c1bea78bec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twitter_scraper\n",
      "  Downloading twitter_scraper-0.4.4-py2.py3-none-any.whl (9.5 kB)\n",
      "Collecting requests-html (from twitter_scraper)\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Collecting MechanicalSoup (from twitter_scraper)\n",
      "  Downloading MechanicalSoup-1.3.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/mamba/lib/python3.10/site-packages (from MechanicalSoup->twitter_scraper) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.7 in /opt/mamba/lib/python3.10/site-packages (from MechanicalSoup->twitter_scraper) (4.12.2)\n",
      "Requirement already satisfied: lxml in /opt/mamba/lib/python3.10/site-packages (from MechanicalSoup->twitter_scraper) (4.9.3)\n",
      "Collecting pyquery (from requests-html->twitter_scraper)\n",
      "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting fake-useragent (from requests-html->twitter_scraper)\n",
      "  Downloading fake_useragent-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting parse (from requests-html->twitter_scraper)\n",
      "  Downloading parse-1.20.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting bs4 (from requests-html->twitter_scraper)\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting w3lib (from requests-html->twitter_scraper)\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyppeteer>=0.0.14 (from requests-html->twitter_scraper)\n",
      "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /opt/mamba/lib/python3.10/site-packages (from beautifulsoup4>=4.7->MechanicalSoup->twitter_scraper) (2.5)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /opt/mamba/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2021 in /opt/mamba/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (2023.11.17)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /opt/mamba/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (6.8.0)\n",
      "Collecting pyee<9.0.0,>=8.1.0 (from pyppeteer>=0.0.14->requests-html->twitter_scraper)\n",
      "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /opt/mamba/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (4.66.1)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /opt/mamba/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html->twitter_scraper) (1.26.18)\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html->twitter_scraper)\n",
      "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests>=2.22.0->MechanicalSoup->twitter_scraper) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests>=2.22.0->MechanicalSoup->twitter_scraper) (3.4)\n",
      "Collecting cssselect>=1.2.0 (from pyquery->requests-html->twitter_scraper)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/mamba/lib/python3.10/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->twitter_scraper) (3.17.0)\n",
      "Downloading MechanicalSoup-1.3.0-py3-none-any.whl (19 kB)\n",
      "Downloading fake_useragent-1.4.0-py3-none-any.whl (15 kB)\n",
      "Downloading parse-1.20.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=c6df9f120a98543ba2a9c2c17b4365a99def312468157819f887208b8a605aa3\n",
      "  Stored in directory: /home/onyxia/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
      "Successfully built bs4\n",
      "Installing collected packages: pyee, parse, fake-useragent, websockets, w3lib, cssselect, pyquery, pyppeteer, MechanicalSoup, bs4, requests-html, twitter_scraper\n",
      "Successfully installed MechanicalSoup-1.3.0 bs4-0.0.1 cssselect-1.2.0 fake-useragent-1.4.0 parse-1.20.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests-html-0.10.0 twitter_scraper-0.4.4 w3lib-2.1.2 websockets-10.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install twitter_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f6f9f7-7670-4a9c-9d47-8bc81ecd10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter_scraper as tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe04cd7b-d411-4fad-8a92-0450130c3055",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tweet_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tw\u001b[38;5;241m.\u001b[39mget_tweets(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melonmusk\u001b[39m\u001b[38;5;124m\"\u001b[39m, pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m     tweet_list\u001b[38;5;241m.\u001b[39mappend(tweet)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/twitter_scraper/modules/tweets.py:170\u001b[0m, in \u001b[0;36mget_tweets\u001b[0;34m(query, pages)\u001b[0m\n\u001b[1;32m    167\u001b[0m         r \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: last_tweet}, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    168\u001b[0m         pages \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m gen_tweets(pages)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/twitter_scraper/modules/tweets.py:37\u001b[0m, in \u001b[0;36mget_tweets.<locals>.gen_tweets\u001b[0;34m(pages)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pages \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         html \u001b[38;5;241m=\u001b[39m HTML(\n\u001b[0;32m---> 37\u001b[0m             html\u001b[38;5;241m=\u001b[39m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems_html\u001b[39m\u001b[38;5;124m\"\u001b[39m], url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbunk\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         )\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOops! Either \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m does not exist or is private.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     42\u001b[0m         )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "tweet_list = []\n",
    "for tweet in tw.get_tweets(\"elonmusk\", pages = 1):\n",
    "    tweet_list.append(tweet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
